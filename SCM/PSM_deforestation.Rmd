---
title: "Synthetic Control Method (Binary Deforestation)"
author: "TJ Sipin"
date: "2023-05-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
# remotes::install_github("ebenmichael/augsynth")
library(MatchIt)
library(lmtest)
library(sandwich)
library(dplyr)
library(ggplot2)
library(tidyverse)
library(kableExtra)
```

In this script, we set our treatment units to be municipalities that have experienced deforestation in the last year. We may extend the synthetic control methods (SCM) to study municipalities that have experienced mining. The target variable is malaria caused by Plasmodium falciparum, though this can be extended to any disease in the data set. In this script, our intervention is binary, whereas a potential future avenue might be to set the intervention to be continuous. We use Plasmodium falciparum malaria since we have more data on it.

## Data

```{r}
full_data <- readRDS("~/peregrine_amazon/data/annual/aad_2021_forests.rds") %>% 
  group_by(Code) %>% 
  mutate(row_number = row_number()) %>% 
  mutate(intervention.st = lag(forest_fragmentation) - forest_fragmentation > 0) %>%
  ungroup() 

# saveRDS(full_data, "~/peregrine_amazon/SCM/deforestation/data/full_data.rds")

intervention_data <- full_data %>% 
  filter(intervention.st == T) %>% 
  group_by(Code) %>% 
  # filter(row_number() == 1) %>%
  complete(Year = Year:2020) %>% # get all years after the initial mining presence
  ungroup() %>% 
  select(Code, Year) %>% 
  unique() %>% 
  # use this key_pair column to access later
  mutate(key_pair = as.character(paste0(as.character(Code), "_", as.character(Year)))) 

# saveRDS(intervention_data, "~/peregrine_amazon/SCM/deforestation/data/intervention_data.rds")
```

Our data is incredibly wide: with `dim(full_data)`. We can reduce the number of variables:

```{r}
data <- full_data %>% 
  filter(!is.na(Pfal.Malaria)) %>%  # remove observations with missing Malaria
  select(# ID vars 
         Code, Name, Country, Year, 
         Pfal.Malaria, intervention.st, forest_density,
         # time-variant vars
         land_use_change, forest_fragmentation, edge_loss,
         NDVI, LST_Day, min_LST_Day, max_LST_Day,
         HNTL, Precip, min_Precip, max_Precip, min_Precip_Month, max_Precip_Month,
         # time-invariant vars
         mean_Elevation, var_Elevation, SWChange_abs, SWRecurrence, SWSeasonality, SWOccurrence) %>% 
  mutate(key_pair = as.character(paste0(as.character(Code), "_", as.character(Year)))) 

# saveRDS(data, "~/peregrine_amazon/SCM/deforestation/data/data.rds")

dim(data)
```

```{r}
data <- readRDS("~/peregrine_amazon/SCM/deforestation/data/data.rds")

# get year of first treatment called intervention
first_intervention_data <- intervention_data %>% 
  # group_by(Code) %>% 
  # filter(row_number() == 1) %>% 
  # ungroup() %>% 
  rename(intervention = Year) %>% 
  select(-key_pair)


data.use <- data %>% 
  mutate(key_pair = as.character(paste0(as.character(Code), "_", as.character(Year)))) %>% 
  group_by(Code) %>% 
  # filter out Peru since there's no data for years before 2016
  # filter(Country != "Peru") %>%
  # mark the observations of deforestation in the municipality
  mutate(deforested = key_pair %in% intervention_data$key_pair) %>% 
  # filter out municipalities that have incomplete data (missing for some years)
  filter(n() == 2020 - 2007 + 1) %>%
  ungroup() %>% 
  # balance the data set by code across all years
  complete(nesting(Code), Year = full_seq(Year, period = 1)) %>% 
  as.data.frame() %>% 
  # merge data with first intervention years
  full_join(first_intervention_data, by=c("Code")) %>% 
  mutate(intervention = ifelse(is.na(intervention),
                               Inf, intervention),
         deforested = 1* (Year >= intervention)) %>% 
  # rearrange variables
  select(Code, Name, Country, Year, Pfal.Malaria, intervention, everything(), -intervention.st, -key_pair) %>% 
  # multisynth needs a few years of pre-intervention in order to work
  # filter(intervention > 2008) %>% 
  # group_by(Code) %>% 
  # # filter(n() > 1) %>% 
  # ungroup() %>% 
  # need as many complete cases as possible, so only filter out missing data for covariates
  filter(across(forest_density:SWOccurrence, ~ !is.na(.x)))

# saveRDS(data.use, "~/peregrine_amazon/SCM/deforestation/data/data.use.rds")
```


We have reduced our number of columns to `r ncol(data)`, which is much better than `r ncol(full_data)`.

Our outcome variable is disease incidence - in this case, Malaria. There is an issue of how to define our intervention variable. We first explore the nature of deforestation for each municipality in our time frame.

```{r}
print(paste("Number of municipalities with deforestation: ", 
            data %>% filter(key_pair %in% intervention_data$key_pair) %>% select(Code) %>% unique() %>% nrow()))
print(paste("Total number of municipalities: ", data %>% select(Code) %>% unique() %>% nrow()))
```


We see that we have 985 municipalities to work with. We now construct a new variable to show when the municipality first saw mining activity.

```{r}
data.use <- readRDS("~/peregrine_amazon/SCM/deforestation/data/data.use.rds")
```


### Set up PSM function

The following takes the above code and puts them into a function to get data based on which forest loss variable to use and how long the lag should be. Then it matches observations based on propensity scores and creates a matched data set to run a generalized linear model (GLM) of `Pfal.Malaria` on the treatment variable (`deforested`). It saves the `matchit` object into `~/peregrine_amazon/SCM/data/` to be called quickly.


```{r}
# https://statsnotebook.io/blog/analysis/matching/#r-codes-for-outcome-analysis-step-2

library(MatchIt)
library(lmtest)
library(sandwich)
library(dplyr)
library(ggplot2)
library(tidyverse)
library(kableExtra)

# use forest_fragmentation or edge_loss or a mix?

psmForestFragmentationFunc <- function(lagYear){
  full_data <- readRDS("~/peregrine_amazon/data/annual/aad_2021_forests.rds") %>%
    group_by(Code) %>%
    mutate(intervention.st = lag(forest_fragmentation, n = lagYear) - forest_fragmentation > 0) %>%
    ungroup()


  intervention_data <- full_data %>%
    filter(intervention.st == T) %>%
    group_by(Code) %>%
    # filter(row_number() == 1) %>%
    complete(Year = Year:2020) %>% # get all years after the initial mining presence
    ungroup() %>%
    select(Code, Year) %>%
    unique() %>%
    # use this key_pair column to access later
    mutate(key_pair = as.character(paste0(as.character(Code), "_", as.character(Year))))

  data <- full_data %>%
    filter(!is.na(Pfal.Malaria)) %>%  # remove observations with missing Malaria
    select(# ID vars
      Code, Name, Country, Year,
      Pfal.Malaria, intervention.st, forest_density,
      # time-variant vars
      land_use_change, forest_fragmentation, edge_loss,
      NDVI, LST_Day, min_LST_Day, max_LST_Day,
      HNTL, Precip, min_Precip, max_Precip, min_Precip_Month, max_Precip_Month,
      # time-invariant vars
      mean_Elevation, var_Elevation, SWChange_abs, SWRecurrence, SWSeasonality, SWOccurrence) %>%
    mutate(key_pair = as.character(paste0(as.character(Code), "_", as.character(Year))))

  # saveRDS(data, "~/peregrine_amazon/SCM/deforestation/data/data.rds")

  # get year of first treatment called intervention
  first_intervention_data <- intervention_data %>%
    # group_by(Code) %>%
    # filter(row_number() == 1) %>%
    # ungroup() %>%
    rename(intervention = Year) %>%
    select(-key_pair)


  data.use <- data %>%
    mutate(key_pair = as.character(paste0(as.character(Code), "_", as.character(Year)))) %>%
    group_by(Code) %>%
    # filter out Peru since there's no data for years before 2016
    # filter(Country != "Peru") %>%
    # mark the observations of deforestation in the municipality
    mutate(deforested = key_pair %in% intervention_data$key_pair) %>%
    # filter out municipalities that have incomplete data (missing for some years)
    filter(n() == 2020 - 2007 + 1) %>%
    ungroup() %>%
    # balance the data set by code across all years
    complete(nesting(Code), Year = full_seq(Year, period = 1)) %>%
    as.data.frame() %>%
    # merge data with first intervention years
    full_join(first_intervention_data, by=c("Code")) %>%
    mutate(intervention = ifelse(is.na(intervention),
                                 Inf, intervention),
           deforested = 1* (Year >= intervention)) %>%
    # rearrange variables
    select(Code, Name, Country, Year, Pfal.Malaria, intervention, everything(), -intervention.st, -key_pair) %>%
    # multisynth needs a few years of pre-intervention in order to work
    # need as many complete cases as possible, so only filter out missing data for covariates
    filter(across(forest_density:SWOccurrence, ~ !is.na(.x)))

  # saveRDS(data.use, "~/peregrine_amazon/SCM/deforestation/data/data.use.rds")

  t0 <- Sys.time()

  # https://statsnotebook.io/blog/analysis/matching/#r-codes-for-outcome-analysis-step-2
  match_obj <- matchit(
    deforested ~
      # forest variables
      forest_density + # land_use_change + forest_fragmentation + edge_loss +
      # environmental variables
      NDVI + LST_Day + min_LST_Day + max_LST_Day +
      HNTL + Precip + min_Precip + max_Precip +
      min_Precip_Month + max_Precip_Month +
      mean_Elevation + var_Elevation +
      SWChange_abs + SWRecurrence + SWSeasonality + SWOccurrence,
    data.use, method = "nearest", distance = "glm", link = 'logit'
  )

  Sys.time() - t0

  saveRDS(match_obj, paste0("~/peregrine_amazon/SCM/data/match_obj_", lagYear, ".rds"))

  summary(match_obj)

  matched_data <- match.data(match_obj)

  # Run regression model with psychological distress as the outcome, and smoker as the only predictor
  # We need to specify the weights - Matched participants have a weight of 1, unmatched participants
  res <- glm(Pfal.Malaria ~ deforested, data = matched_data, weights = weights, family = "quasipoisson")

  summary(res)

  # Test the coefficient using cluster robust standard error
  coeftest(res, vcov. = vcovCL, cluster = ~subclass)
  # Calculate confidence intervals based on cluster robust standard error
  coefci(res, vcov. = vcovCL, cluster = ~subclass, level = 0.95)
}

psmEdgeLossFunc <- function(lagYear){
  full_data <- readRDS("~/peregrine_amazon/data/annual/aad_2021_forests.rds") %>%
    group_by(Code) %>%
    mutate(intervention.st = lag(edge_loss, n = lagYear) - edge_loss > 0) %>%
    ungroup()


  intervention_data <- full_data %>%
    filter(intervention.st == T) %>%
    group_by(Code) %>%
    # filter(row_number() == 1) %>%
    complete(Year = Year:2020) %>% # get all years after the initial mining presence
    ungroup() %>%
    select(Code, Year) %>%
    unique() %>%
    # use this key_pair column to access later
    mutate(key_pair = as.character(paste0(as.character(Code), "_", as.character(Year))))

  data <- full_data %>%
    filter(!is.na(Pfal.Malaria)) %>%  # remove observations with missing Malaria
    select(# ID vars
      Code, Name, Country, Year,
      Pfal.Malaria, intervention.st, forest_density,
      # time-variant vars
      land_use_change, forest_fragmentation, edge_loss,
      NDVI, LST_Day, min_LST_Day, max_LST_Day,
      HNTL, Precip, min_Precip, max_Precip, min_Precip_Month, max_Precip_Month,
      # time-invariant vars
      mean_Elevation, var_Elevation, SWChange_abs, SWRecurrence, SWSeasonality, SWOccurrence) %>%
    mutate(key_pair = as.character(paste0(as.character(Code), "_", as.character(Year))))

  # saveRDS(data, "~/peregrine_amazon/SCM/deforestation/data/data.rds")

  # get year of first treatment called intervention
  first_intervention_data <- intervention_data %>%
    # group_by(Code) %>%
    # filter(row_number() == 1) %>%
    # ungroup() %>%
    rename(intervention = Year) %>%
    select(-key_pair)


  data.use <- data %>%
    mutate(key_pair = as.character(paste0(as.character(Code), "_", as.character(Year)))) %>%
    group_by(Code) %>%
    # filter out Peru since there's no data for years before 2016
    # filter(Country != "Peru") %>%
    # mark the observations of deforestation in the municipality
    mutate(deforested = key_pair %in% intervention_data$key_pair) %>%
    # filter out municipalities that have incomplete data (missing for some years)
    filter(n() == 2020 - 2007 + 1) %>%
    ungroup() %>%
    # balance the data set by code across all years
    complete(nesting(Code), Year = full_seq(Year, period = 1)) %>%
    as.data.frame() %>%
    # merge data with first intervention years
    full_join(first_intervention_data, by=c("Code")) %>%
    mutate(intervention = ifelse(is.na(intervention),
                                 Inf, intervention),
           deforested = 1* (Year >= intervention)) %>%
    # rearrange variables
    select(Code, Name, Country, Year, Pfal.Malaria, intervention, everything(), -intervention.st, -key_pair) %>%
    # multisynth needs a few years of pre-intervention in order to work
    # need as many complete cases as possible, so only filter out missing data for covariates
    filter(across(forest_density:SWOccurrence, ~ !is.na(.x)))

  # saveRDS(data.use, "~/peregrine_amazon/SCM/deforestation/data/data.use.rds")

  t0 <- Sys.time()

  # https://statsnotebook.io/blog/analysis/matching/#r-codes-for-outcome-analysis-step-2
  match_obj <- matchit(
    deforested ~
      # forest variables
      forest_density + # land_use_change + forest_fragmentation + edge_loss +
      # environmental variables
      NDVI + LST_Day + min_LST_Day + max_LST_Day +
      HNTL + Precip + min_Precip + max_Precip +
      min_Precip_Month + max_Precip_Month +
      mean_Elevation + var_Elevation +
      SWChange_abs + SWRecurrence + SWSeasonality + SWOccurrence,
    data.use, method = "nearest", distance = "glm", link = 'logit'
  )

  Sys.time() - t0

  saveRDS(match_obj, paste0("~/peregrine_amazon/SCM/data/match_obj_", lagYear, ".rds"))

  summary(match_obj)

  matched_data <- match.data(match_obj)

  # Run regression model with psychological distress as the outcome, and smoker as the only predictor
  # We need to specify the weights - Matched participants have a weight of 1, unmatched participants
  res <- glm(Pfal.Malaria ~ deforested, data = matched_data, weights = weights, family = "quasipoisson")

  summary(res)

  # Test the coefficient using cluster robust standard error
  coeftest(res, vcov. = vcovCL, cluster = ~subclass)
  # Calculate confidence intervals based on cluster robust standard error
  coefci(res, vcov. = vcovCL, cluster = ~subclass, level = 0.95)
}

psmForestFragmentationFunc(1)
psmForestFragmentationFunc(2)
psmForestFragmentationFunc(3)
psmForestFragmentationFunc(4)
psmForestFragmentationFunc(5)

psmEdgeLossFunc(1)
psmEdgeLossFunc(2)
psmEdgeLossFunc(3)
psmEdgeLossFunc(4)
psmEdgeLossFunc(5)
```





